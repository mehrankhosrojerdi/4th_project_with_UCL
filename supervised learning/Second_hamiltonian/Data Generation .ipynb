{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Haldane_spin_half import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "L = 5 # should be odd\n",
        "bond = 5\n",
        "HaldaneSpinHalf = HaldaneSpinHalf(L = L, bond = bond)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state, targets = HaldaneSpinHalf.generate_train_set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(220,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_points = pd.read_csv('~/4th_project_with_UCL/supervised learning/Second_hamiltonian/dataset/regular_train_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mehran/.local/lib/python3.10/site-packages/cotengra/hyperoptimizers/hyper.py:33: UserWarning: Couldn't import `kahypar` - skipping from default hyper optimizer and using basic `labels` method instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import h5py\n",
        "import quimb as qu\n",
        "import quimb.tensor as qtn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import *\n",
        "import matplotlib.pyplot as plt\n",
        "from Haldane_spin_half import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "L = 11  # number of particle which has to be odd for calculate faster\n",
        "ls_train = 11 # the scale of dividing the range of h and k for train part (including projected states)\n",
        "ls_test = 11 # the scale of dividing the range of h and k for test part (including DMRG states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "495"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set = ANNNI(L = L, ls = ls_train).generate_train_set() #ts[0] = DMRG_state, ts[1] = DMRG_target, ts[2] = project_state,ts[3] = projection_target, ts[4] = h1_h2\n",
        "gc.collect(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "with h5py.File(\"projection_target.hdf5\", \"w\") as f:\n",
        "    f.create_dataset(\"y\", data = train_set[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "test_set = ANNNI(L = L, ls = ls_test).generate_test_set()#ts[0]=DMRG_state, ts[1]=h1h2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gram_train():\n",
        "    Xt = train_set[2]\n",
        "    d = len(Xt)\n",
        "    gram_matrix_train = np.zeros((d,d))\n",
        "    for i in range(d):\n",
        "        for j in range(d):\n",
        "            gram_matrix_train[i,j] = np.abs(Xt[i].H @ Xt[j])**2/ (np.abs(Xt[i].H @ Xt[i])*np.abs(Xt[j].H @ Xt[j]))\n",
        "    return gram_matrix_train\n",
        "\n",
        "gtrain = gram_train()\n",
        "\n",
        "with h5py.File(\"gram_train.hdf5\", \"w\") as f:\n",
        "    f.create_dataset(\"gram_train\", data = gram_train())\n",
        "\n",
        "gc.collect(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "metadata": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gram_test():\n",
        "    Xte = test_set[0]\n",
        "    d1 = len(Xte)\n",
        "    Xtr = train_set[2]\n",
        "    d2 = len(Xtr)\n",
        "    gram_matrix_test = np.zeros((d1,d2))\n",
        "    for i in range(d1):\n",
        "        for j in range(d2):\n",
        "            gram_matrix_test[i,j] = np.abs((Xte[i].H @ Xtr[j]))**2/ (np.abs((Xte[i].H @ Xte[i]))*np.abs((Xtr[j].H @ Xtr[j])))\n",
        "    return gram_matrix_test\n",
        "\n",
        "gtest = gram_test()\n",
        "\n",
        "with h5py.File(\"gram_test.hdf5\", \"w\") as f:\n",
        "    f.create_dataset(\"gram_test\", data = gram_test())\n",
        "\n",
        "gc.collect(2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TN_QML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
